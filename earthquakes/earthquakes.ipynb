{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'database.csv'\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "data = data[data['Type'] == 'Earthquake']\n",
    "\n",
    "bad_cols = ['Magnitude Error','Magnitude Seismic Stations','Azimuthal Gap','Horizontal Distance',\n",
    "            'Horizontal Error','Root Mean Square', 'Type', 'ID', 'Depth Error', 'Depth Seismic Stations',\n",
    "            'Date', 'Time']\n",
    "\n",
    "\n",
    "data['Longitude'] = np.sin(data['Longitude'])\n",
    "data['Latitude'] = np.sin(data['Latitude'])\n",
    "\n",
    "data['dt'] = data['Date'] + ' ' + data['Time']\n",
    "\n",
    "\n",
    "bad_rows = []\n",
    "for idx in range(len(data)):\n",
    "    try:\n",
    "        t = data['dt'][idx]\n",
    "        if 'T' in t:\n",
    "            bad_rows += [idx]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "data = data.drop(bad_rows, axis=0)\n",
    "data = data.drop(bad_cols, axis=1)\n",
    "\n",
    "# some stuff to use datetime class\n",
    "dater = lambda t: datetime.datetime.strptime(t, \"%m/%d/%Y %H:%M:%S\")\n",
    "map_time = np.vectorize(dater)\n",
    "dt = maper(data['dt'])\n",
    "epoch = datetime.datetime(1965, 1, 1)\n",
    "delta = (dt-epoch)\n",
    "\n",
    "# converting data_time to seconds\n",
    "map_seconds = np.vectorize(lambda t: t.total_seconds())\n",
    "data['dt'] = map_seconds(delta)\n",
    "\n",
    "# converting string classification data to numbers\n",
    "for item_name in data.dtypes[data.dtypes == 'object'].index.values:\n",
    "    map_dict = {}\n",
    "    for item in pd.Series(data[item_name]).unique():\n",
    "            map_dict[item] = len(map_dict)\n",
    "\n",
    "    data[item_name].replace(to_replace=map_dict, inplace=True)\n",
    "\n",
    "data.dropna()\n",
    "\n",
    "Y = data['Magnitude']\n",
    "X = data.drop('Magnitude', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "gbm = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05).fit(X_train, y_train)\n",
    "predictions = gbm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26583755919070207\n"
     ]
    }
   ],
   "source": [
    "print((y_test-predictions).dot(y_test-predictions) / len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we have accuracy about 0.5 in predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
