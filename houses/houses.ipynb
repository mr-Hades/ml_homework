{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.base import TransformerMixin\n",
    "import lightgbm as lgb\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'train.csv'\n",
    "test_path = 'test.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_path)\n",
    "test_data = pd.read_csv(test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = list(range(1,14)) + [-1]\n",
    "# train_data.iloc[:,columns].dropna(axis=0, how='any', inplace=True)\n",
    "#################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_data = pd.concat([train_data, test_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_train = big_data\n",
    "\n",
    "dt = pd.to_datetime(trans_train['timestamp'])\n",
    "trans_train['timestamp'] = dt.astype(np.int64) // 10 ** 9\n",
    "# pd.Series(trans_train['sub_area']).unique()\n",
    "trans_train['sub_area'] = 'sub_area_' + trans_train['sub_area']\n",
    "# new_cols = pd.Series(trans_train['sub_area']).unique()\n",
    "one_hots = pd.get_dummies(pd.Series(trans_train['sub_area']))\n",
    "trans_train=pd.concat([trans_train,one_hots],axis=1)\n",
    "\n",
    "yes_no_cols = ['thermal_power_plant_raion','incineration_raion','oil_chemistry_raion',\n",
    "               'radiation_raion','railroad_terminal_raion','big_market_raion','nuclear_reactor_raion',\n",
    "               'detention_facility_raion','big_road1_1line','railroad_1line','water_1line']\n",
    "\n",
    "yes_no_dict = {'yes':1, 'no':0}\n",
    "[trans_train[item].replace(yes_no_dict, inplace=True) for item in yes_no_cols]\n",
    "\n",
    "ecology_dict = {'good':2, 'excellent':3, 'poor':0, 'satisfactory':1, 'no data':1}\n",
    "trans_train['ecology'].replace(ecology_dict, inplace=True)\n",
    "\n",
    "prod_dict = {'Investment':0, 'OwnerOccupier':1}\n",
    "trans_train['product_type'].replace(prod_dict, inplace=True)\n",
    "\n",
    "bad_cols = ['culture_objects_top_25', 'sub_area']\n",
    "trans_train.drop(bad_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(train_data)\n",
    "y_train = trans_train[:train_size][['price_doc']]\n",
    "\n",
    "tr_train = trans_train.dropna(axis=1, inplace=False)\n",
    "\n",
    "# tr_train = trans_train.fillna(trans_train.mean())\n",
    "x_train = tr_train[:train_size]\n",
    "x_test = tr_train[len(train_data):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trans(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, data_frame):\n",
    "        return data_frame\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self\n",
    "\n",
    "class XGRegr(XGBRegressor):\n",
    "    def __init__(self, max_depth=3, learning_rate=0.1, n_estimators=100, silent=True,\n",
    "                 objective='reg:linear', booster='gbtree', n_jobs=1, nthread=None,\n",
    "                 gamma=0, min_child_weight=1, max_delta_step=0, subsample=1,\n",
    "                 colsample_bytree=1, colsample_bylevel=1, reg_alpha=0,\n",
    "                 reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0,\n",
    "                 seed=None, missing=None, **kwargs):\n",
    "        \n",
    "        super().__init__(max_depth=max_depth, learning_rate=learning_rate, n_estimators=n_estimators, silent=silent,\n",
    "                         objective=objective, booster=booster, n_jobs=n_jobs, nthread=nthread,\n",
    "                         gamma=gamma, min_child_weight=min_child_weight, max_delta_step=max_delta_step, subsample=subsample,\n",
    "                         colsample_bytree=colsample_bytree, colsample_bylevel=colsample_bylevel, reg_alpha=reg_alpha,\n",
    "                         reg_lambda=reg_lambda, scale_pos_weight=scale_pos_weight, base_score=base_score, random_state=random_state,\n",
    "                         seed=seed, missing=missing, **kwargs)\n",
    "        \n",
    "    def transform(self, *args):\n",
    "        return self.predict(*args).reshape(-1,1)\n",
    "\n",
    "lr_mod = linear_model.LinearRegression()\n",
    "lr_mod.transform = lr_mod.predict\n",
    "\n",
    "lr1_mod = linear_model.LinearRegression()\n",
    "lr1_mod.transform = lr_mod.predict\n",
    "\n",
    "xgb1 = XGRegr(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n",
    "                           colsample_bytree=1, max_depth=7)\n",
    "\n",
    "xgb2 = XGRegr(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n",
    "                           colsample_bytree=1, max_depth=7)\n",
    "\n",
    "trans = Trans()\n",
    "\n",
    "# pca = PCA(n_components=200, svd_solver='arpack')\n",
    "# pca.fit_transform(x_train).shape\n",
    "\n",
    "# estimators = [('linear_regr', lr_mod), ('xgb1', xgb1), ('empty', trans)]\n",
    "# estimators = [('linear_regr', lr_mod), ('empty', trans)]\n",
    "estimators = [('empty', trans)]\n",
    "# estimators = [('pca', pca)]\n",
    "united = FeatureUnion(estimators)\n",
    "pipe = Pipeline([('feature_union', united), ('xgb2', xgb2)])\n",
    "# pipe = Pipeline([('feature_union', united), ('lr1', lr1_mod)])\n",
    "pipe.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feature_union', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('empty', <__main__.Trans object at 0x7f04f3efd160>)],\n",
       "       transformer_weights=None)), ('xgb2', XGRegr(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "    colsample_bytree=1, gamma=0, learning_rate=0.08, max_delta_ste...=0,\n",
       "    reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "    subsample=0.75))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there is no point in this structure ofcourse, its done just for usage of featureunion and pipeline,\n",
    "# as the best result is gained by just removing all columns with nan data and using xgboost\n",
    "# the Kaggle score for it is 0.338\n",
    "\n",
    "# In this homework I haven't made the transformer function for data but will do the for flask homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_test[x_test.isnull()])\n",
    "\n",
    "y_test = pipe.predict(x_test.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "x_test['price_doc'] = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[['id', 'price_doc']].to_csv('soln.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
